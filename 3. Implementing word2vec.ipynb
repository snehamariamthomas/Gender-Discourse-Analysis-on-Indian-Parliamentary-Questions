{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final_dataset refers to dataset obtained from combining TCPD-IPD questions with the webscraped questions from 2019-2024 \n",
    "url = \"final_dataset.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT PRE-PROCESSING\n",
    "\n",
    "df['answer_text'] = df['answer_text'].astype(str)\n",
    "df['subject']= df['subject'].astype(str)\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only alphabets and spaces\n",
    "    return cleaned_text\n",
    "df['answer_text'] = df['answer_text'].apply(clean_text)\n",
    "\n",
    "\n",
    "# Remove 'answer' (case insensitive)\n",
    "df['answer_text'] = df['answer_text'].str.replace('answer', ' ', case=False)\n",
    "\n",
    "# List of Indian states and capitals\n",
    "indian_states = [\n",
    "    'Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Chhattisgarh', 'Goa', 'Gujarat', 'Haryana',\n",
    "    'Himachal Pradesh', 'Jharkhand', 'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur',\n",
    "    'Meghalaya', 'Mizoram', 'Nagaland', 'Odisha', 'Punjab', 'Rajasthan', 'Sikkim', 'Tamil Nadu', 'Telangana',\n",
    "    'Tripura', 'Uttarakhand', 'Uttar Pradesh', 'West Bengal', 'Andaman and Nicobar Islands', 'Chandigarh',\n",
    "    'Dadra' 'Nagar Haveli', 'Daman', 'Diu', 'NCT' , 'Jammu' 'Kashmir', 'Ladakh',\n",
    "    'Lakshadweep', 'Puducherry'\n",
    "]\n",
    "\n",
    "indian_capitals = [\n",
    "    'Amaravati', 'Itanagar', 'Dispur', 'Patna', 'Raipur', 'Panaji', 'Gandhinagar', 'Chandigarh', 'Shimla',\n",
    "    'Ranchi', 'Bangalore', 'Thiruvananthapuram', 'Bhopal', 'Mumbai', 'Imphal', 'Shillong', 'Aizawl', 'Kohima',\n",
    "    'Bhubaneshwar', 'Chandigarh', 'Jaipur', 'Gangtok', 'Chennai', 'Hyderabad', 'Agartala', 'Dehradun', 'Lucknow',\n",
    "    'Kolkata', 'Port Blair', 'Chandigarh', 'Daman', 'Delhi', 'Srinagar, Jammu', 'Leh', 'Kavaratti', 'Puducherry'\n",
    "]\n",
    "\n",
    "# Function to remove Indian states and capitals from text\n",
    "def remove_indian_places(text):\n",
    "    # Compile regex pattern to match all Indian states and capitals\n",
    "    pattern = re.compile(r'\\b(?:' + '|'.join(map(re.escape, indian_states + indian_capitals)) + r')\\b', flags=re.IGNORECASE)\n",
    "    # Substitute matched words with empty string\n",
    "    cleaned_text = pattern.sub('', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to the 'answer_text' column\n",
    "df['answer_text'] = df['answer_text'].apply(remove_indian_places)\n",
    "\n",
    "\n",
    "#REMOVE Minister of State line\n",
    "import re\n",
    "def remove_prefix(text):\n",
    "    # Define the pattern to match the prefix\n",
    "    pattern = r'^(the\\s+)?minister\\s+of\\s+state\\s*'\n",
    "    # Search for the pattern\n",
    "    match = re.match(pattern, text, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        # Remove the prefix and words until the first occurrence of a single alphabet 'a/A'\n",
    "        return re.sub(r'^.*?(\\s[a-zA-Z]\\s|$)', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "df['answer_text'] = df['answer_text'].apply(remove_prefix)\n",
    "df['answer_text'] = df['answer_text'].str.lstrip()\n",
    "\n",
    "# Remove single occurring alphabets\n",
    "df['answer_text'] = df['answer_text'].str.strip()  \n",
    "df['answer_text'] = df['answer_text'].str.replace(r'\\b\\w\\b', '', regex=True)\n",
    "\n",
    "#Lowercase\n",
    "df['answer_text'] = df['answer_text'].str.lower()\n",
    "df['answer_text'] = df['answer_text'].str.strip()\n",
    "\n",
    "\n",
    "# Removing certain non-semantic words\n",
    "def remove_words(text):\n",
    "    words_to_remove = ['no', 'yes', 'madam', 'answer', 'answers', 'question', \n",
    "                       'statement', 'table', 'laid', 'reply', 'ministry', \n",
    "                       'sushri', 'shri', 'shrimati', 'dr']\n",
    "    for word in words_to_remove:\n",
    "        text = re.sub(r'\\b{}\\b'.format(re.escape(word)), '', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Assuming df['answer_text'] contains the text data\n",
    "df['answer_text'] = df['answer_text'].apply(remove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating answer,question and subject\n",
    "\n",
    "df['full_text'] = df['subject'] + ' ' + df['question_text']+' ' + df['answer_text']\n",
    "df['full_text'] = df['full_text'].str.lower() \n",
    "\n",
    "nan_indices = df[df['question_text'].isnull()].index\n",
    "df = df.drop(nan_indices)\n",
    "df['full_text']= df['full_text'].astype(str)\n",
    "\n",
    "\n",
    "#REMOVING STOP WORDS EXCEPT GENDERED ONES\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords list (if not already downloaded)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove specific words from the set of stopwords\n",
    "words_to_keep = {\"she\", \"her\", \"hers\", \"herself\", \"she's\", \"she'd\", \"she'll\"}\n",
    "stop_words.difference_update(words_to_keep)\n",
    "\n",
    "# Function to remove stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Remove stopwords, excluding specific words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    # Join the filtered words back into a single string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "# Apply the function to the 'full_text' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD2VEC: BIGRAMS\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "sent = [row.split() for row in df['full_text']]\n",
    "phrases = Phrases(sent, min_count=5, progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP GRAM\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "skipg = Word2Vec(min_count=20,\n",
    "                     window=6,\n",
    "                     vector_size=300,  \n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1,\n",
    "                     sg=1)\n",
    "\n",
    "skipg.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "skipg_model = skipg.train(sentences, total_examples=skipg.corpus_count, epochs=20, report_delay=1)  \n",
    "#159 min\n",
    "\n",
    "#skipg.save(\"path/skipg-full.model\")\n",
    "\n",
    "#Identifying most similar words to women\n",
    "skipg.wv.most_similar(positive=[\"woman\"], topn=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBOW\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "\n",
    "word_embed = Word2Vec(min_count=20,\n",
    "                     window=6,\n",
    "                     vector_size=300,  # Corrected parameter name\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)\n",
    "\n",
    "\n",
    "word_embed.build_vocab(sentences, progress_per=10000)\n",
    "word_embed_model = word_embed.train(sentences, total_examples=word_embed.corpus_count, epochs=20, report_delay=1)\n",
    "#48 min\n",
    "\n",
    "#word_embed.save(\"path/cbow-full.model\")\n",
    "word_embed.wv.most_similar(positive=[\"woman\"], topn=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on words identified by word embedding models categorising questions on whetehr they pertain to women or not\n",
    "\n",
    "import pandas as pd\n",
    "df_final = df.copy()\n",
    "\n",
    "# Define the regular expression pattern\n",
    "pattern = r\"female.*|girl.*|\\bladies\\b|\\bqueen(s?)\\b|\\bwom(a|e)n.*|\\bbride.*\\b|daughter.*|\\bdivorce.*\\b|\\b.*mother.*\\b|\\bhousemaid.*\\b|\\bhusband(s?)\\b|\\bmarital.*\\b|\\b.*marriage.*\\b|\\b.*married\\b|\\bmarry.*\\b|\\bmatrimonial.*\\b|\\bpregnan.*\\b|sister(s?)|\\bson(s?)\\b|\\bspouse(s?)\\b|\\bwidow.*\\b|\\bwife\\b|\\bwives\\b|\\babduct.*\\b|\\babortion(s?)\\b|\\bacid(s?)(\\s?)attack(s?)|\\b(victim(s?))(\\s?)(acid(s?))\\b.*hostess(es?)\\b|\\b.*natal.*\\b|\\bbreast.*\\b|\\bbrothel(s?)\\b|\\bchild(\\s?)birth(s?)\\b|\\bchild(\\s?)care(s?)\\b|\\bcontracept.*\\b|\\bcreche|\\bcsection\\b|\\bdomestic(\\s?)violence(s?)\\b|\\bdowry.*\\b|\\beve((-?)|(\\s?))teasing\\b|\\b(first(s?)|second(s?)|third(s?))(\\s?)trimester(s?)\\b|\\bfoetus\\b|\\bfoetal\\b|\\bfolic(\\s?)acid\\b|\\bgang((-?)|(\\s?))rape(s?)\\b|\\b.*gender.*\\b|\\bgynae.*\\b|\\bifa(\\s?)tablet(s?)\\b|\\b(human(s?)|child|children|wom(a|e)n)(\\s?)trafficked\\b|\\bimmoral(s?)traffic.*\\b|\\b(human(s?)|child|children|wom(a|e)n)(\\s?)trafficking\\b|\\binfanticide(s?)\\b|\\binstitutional(\\s?)deliver.*\\b|\\bkidnap.*\\b|\\blactati.*\\b|\\bmarital.*\\b|\\bmatern.*\\b|\\bmedical(\\s?)terminat.*\\b|\\bmenstrua.*\\b|\\bmolest.*\\b|\\bnursing.*\\b|\\bobstetri.*\\b|\\bprostitut.*\\b|\\brape.*\\b|\\brapist(s?)\\b|\\breproducti.*\\b|\\bsati\\b|\\bsex.*\\b|\\bstalking\\b|\\bsupplementation(\\s?)iron\\b|\\biron(\\s?)supplement(s?)\\b|\\bsurroga.*\\b|tubectomy|vasectomy|\\bvictims(\\s?)acid(s?)\\b|a(a?)nganwadi(s?)|\\baccredited(\\s?)social|\\banm(s?)\\b|midfwife|midwives|\\barsh\\b|\\basha(s?).*\\b|\\baww(s?)\\b|\\bbbbp\\b|\\bbirth(\\s?)attendant(s?)\\b|creche(s?)|\\bdhan(a?)(\\s?)lakshmi\\b|dwcra|\\binternal(\\s?)(complaint(s?))(\\s?)committee(s?)\\b|\\bigmsy\\b|\\bjssk\\b|\\bjsy\\b|\\bkiran\\b|\\bmatritva\\b|\\bmatru\\b|\\bmilitary(\\s?)nursing(\\s?)service(\\s?)\\b|\\bmwcd\\b|\\bncw\\b|\\bnmbs\\b|\\bnmew\\b|\\bpcma\\b|\\bpcpndt\\b|\\bppmmvy\\b|\\bpocso\\b|\\bpoorna(\\s?)shakti\\b|\\bpriyadarshini\\b|\\bpwdva\\b|\\bsavita\\b|\\bshishu(\\s?)suraksha\\b|\\bsneh(a?)\\b|\\bssh\\b|\\bshort(\\s?)stay(\\s?)home(s?)\\b|\\bswadhar\\b|\\bswashakti\\b|\\bswayamsiddh(a?)\\b|\\bujjawala\\b|\\bvandana\\b|\\bvishaka\\b|\\bwwh\\b|\\bwomen(\\s?)hostel(s?)\\b|\\bbeti\\b|\\bdai(s?)\\b|\\bdevdasi(s?)\\b|\\bjanani.*|\\bksihori|\\bmahila|sakhi(s?)|\\banc\\b|caesarean|\\bgdm\\b|gestational|\\bhome(\\s?)deliver.*\\b|intrauterine|matrimonial|miscarriage(s?)|postpartum|ppiucd|pwlm|sabla|thyroid|uterus|awc(s?)|\\bcmb\\b|laqshya|\\bmcp\\b|\\bmpv\\b|\\bsakhi\\b|\\bshakti\\b|\\bsukanya\\b|\\bsuman\\b|\\bswarnima\\b|\\btejaswini\\b|\\bwifs\\b|\\bwhl\\b|\\bwosc\\b\"\n",
    "\n",
    "compiled_pattern = re.compile(pattern)\n",
    "df_final['is_gender'] = df_final['full_text'].apply(lambda x: 'g' if compiled_pattern.search(x) else 'ng')\n",
    "\n",
    "#Tells question count\n",
    "df_final['is_gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for topic modelling\n",
    "embed_gender = df_final[df_final['is_gender'] == 'g']\n",
    "embed_gender.to_csv('Gender_New.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
